{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11450933,"sourceType":"datasetVersion","datasetId":7174491}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Installation\n\n","metadata":{"id":"vGLMBeNg-CHh"}},{"cell_type":"code","source":"pip install wandb numpy pandas matplotlib torch torchvision","metadata":{"id":"TDRNq2wV9Yxr"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Dataset","metadata":{"id":"2pKvVtLV-TqH"}},{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zftJw42q-LCj","outputId":"5278f293-4ccc-4159-9e93-bfe67cf1ba47"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"execution_count":1},{"cell_type":"code","source":"#!unzip /content/drive/MyDrive/DL_Assignment2/Dataset/nature_12K.zip -d /content/drive/MyDrive/DL_Assignment2/Dataset","metadata":{"id":"Vk6BRhrcAydF","collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Libraries","metadata":{"id":"4cSWu4KFCJLE"}},{"cell_type":"code","source":"import torch\nimport os\nfrom torchvision import datasets, transforms\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\nfrom torch.utils.data import Subset, DataLoader\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nimport wandb\nimport tqdm\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"id":"6a0b6a18CMBf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f179747b-00b2-49e6-e5b0-0b4547cc7d4a","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T09:56:14.206862Z","iopub.execute_input":"2025-04-18T09:56:14.207054Z","iopub.status.idle":"2025-04-18T09:56:25.092963Z","shell.execute_reply.started":"2025-04-18T09:56:14.207036Z","shell.execute_reply":"2025-04-18T09:56:25.092242Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Dataset loader","metadata":{"id":"lF5ZbaMoGFGm"}},{"cell_type":"code","source":"def validationDataSplit(train_dataset):\n  classLabels = [label for _,label in train_dataset.samples]\n  num_classes = len(np.unique(classLabels))\n\n  sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n  train_indices, val_indices = next(sss.split(train_dataset.samples, classLabels))\n\n  train_subset = Subset(train_dataset, train_indices)\n  val_subset = Subset(train_dataset, val_indices)\n  return train_subset, val_subset, num_classes\n\n\ndef load_data(base_dir, isDataAug):\n  train_dir = os.path.join(base_dir, 'train')\n  test_dir = os.path.join(base_dir, 'val')\n\n  train_transform, test_transform = None, None\n\n  if isDataAug == False:\n    train_transform = transforms.Compose([\n      transforms.Resize(256),\n      transforms.CenterCrop(224),\n      transforms.ToTensor(),\n      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n  else:\n    train_transform = transforms.Compose([\n      transforms.Resize(256),\n      transforms.CenterCrop(224),\n      transforms.RandomHorizontalFlip(),\n      transforms.RandomRotation(10),\n      transforms.ToTensor(),\n      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\n  test_transform = transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n\n  train_dataset = datasets.ImageFolder(train_dir, transform=train_transform)\n  test_dataset = datasets.ImageFolder(test_dir, transform=test_transform)\n  train_dataset, val_dataset, num_classes = validationDataSplit(train_dataset)\n\n  # print(f\"inp: {train_dataset[0][0].shape} {train_dataset[0][1]}\")\n\n  train_loader = DataLoader(train_dataset,shuffle=True,num_workers=2,batch_size=64,pin_memory=True)\n  test_loader = DataLoader(test_dataset,shuffle=True,num_workers=2,batch_size=64,pin_memory=True)\n  val_loader = DataLoader(val_dataset,shuffle=True,num_workers=2,batch_size=64,pin_memory=True)\n\n  return train_loader, test_loader, val_loader, num_classes\n\n# load_data(\"/content/drive/MyDrive/DL_Assignment2/Dataset/inaturalist_12K/\", True)","metadata":{"id":"17mDOMKWGIGJ","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T09:56:32.129850Z","iopub.execute_input":"2025-04-18T09:56:32.130095Z","iopub.status.idle":"2025-04-18T09:56:32.138245Z","shell.execute_reply.started":"2025-04-18T09:56:32.130077Z","shell.execute_reply":"2025-04-18T09:56:32.137567Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Network","metadata":{"id":"5T2fCf1l2ZJF"}},{"cell_type":"code","source":"class ConvolutionalNeuralNetwork(nn.Module):\n  activationFunctionsMap = {\"ReLU\": nn.ReLU, \"GELU\": nn.GELU, \"SiLU\": nn.SiLU}\n  # optimizersMap = {\"sgd\": optim.SGD, \"rmsprop\": optim.RMSprop, \"adam\": optim.Adam}\n\n  def __init__(self, num_classes,\n               num_filters, filter_sizes,\n               activationFun, optimizer,\n               n_neurons_denseLayer,\n               isBatchNormalization, dropout,\n               learning_rate=0.001,\n               momentum=0.5, beta = 0.9,\n               beta1=0.9, beta2=0.99,\n               epsilon=1e-8, weight_decay=0.0001):\n    super(ConvolutionalNeuralNetwork, self).__init__()\n    self.num_classes = num_classes\n    self.num_filters = num_filters\n    self.filter_sizes = filter_sizes\n    self.activationFun = ConvolutionalNeuralNetwork.activationFunctionsMap[activationFun]\n    # self.optimizer = ConvolutionalNeuralNetwork.optimizersMap[optimizer]\n\n    self.n_neurons_denseLayer = n_neurons_denseLayer\n    self.isBatchNormalization = isBatchNormalization\n    self.dropout = dropout\n\n    self.lr = learning_rate\n    self.momentum = momentum\n    self.betas = (beta1, beta2)\n    self.eps = epsilon\n    self.alpha = beta\n    self.weight_decay = weight_decay\n\n    self.defineModel()\n\n    if(optimizer == \"sgd\"):\n      self.optimizer = optim.SGD(self.parameters(), lr=self.lr, momentum=self.momentum, weight_decay=self.weight_decay)\n    elif(optimizer == \"rmsprop\"):\n      self.optimizer = optim.RMSprop(self.parameters(), lr=self.lr, alpha=self.alpha, eps=self.eps, weight_decay=self.weight_decay)\n    elif(optimizer == \"adam\"):\n      self.optimizer = optim.Adam(self.parameters(), lr=self.lr, betas=self.betas, eps=self.eps, weight_decay=self.weight_decay)\n\n\n\n  def defineModel(self):\n    self.model = nn.Sequential()\n\n    inChannels = 3;     # RGB channels for inaturalist\n    for i in range(len(self.num_filters)):\n      self.model.append(nn.Conv2d(inChannels, self.num_filters[i], self.filter_sizes[i], padding=self.filter_sizes[i]//2))\n      if self.isBatchNormalization:\n        self.model.append(nn.BatchNorm2d(self.num_filters[i]))\n      self.model.append(self.activationFun())\n      self.model.append(nn.MaxPool2d(kernel_size=2))\n      inChannels = self.num_filters[i]\n\n    # computing flattened size\n    input_shape = (3, 224, 224)\n    with torch.no_grad():\n      dummy_input = torch.zeros(1, *input_shape)\n      dummy_output = self.model(dummy_input)\n      flattened_size = dummy_output.view(dummy_output.size(0), -1).size(1)\n\n    self.model.append(nn.Flatten())\n    self.model.append(nn.Linear(flattened_size, self.n_neurons_denseLayer))\n    self.model.append(self.activationFun())\n\n    if(self.dropout > 0):\n      self.model.append(nn.Dropout(self.dropout))\n\n    self.model.append(nn.Linear(self.n_neurons_denseLayer, self.num_classes))\n\n  def forward(self, inputs):\n    return self.model(inputs)\n\n  def backward(self, outputs, labels):\n    loss = nn.CrossEntropyLoss()(outputs, labels)\n    loss.backward()\n\n  def updateWeights(self):\n    self.optimizer.step()","metadata":{"id":"RVUtdV4T2bAx","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T09:56:34.752784Z","iopub.execute_input":"2025-04-18T09:56:34.753331Z","iopub.status.idle":"2025-04-18T09:56:34.763827Z","shell.execute_reply.started":"2025-04-18T09:56:34.753308Z","shell.execute_reply":"2025-04-18T09:56:34.763012Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## Training CNN","metadata":{"id":"eHcPcof_tmdc"}},{"cell_type":"code","source":"sweep_configuration = {\n    \"method\": \"bayes\",\n    \"name\" : \"train_sweep\",\n    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n    \"parameters\": {\n        \"num_filters\": {'values': [[32, 32, 32, 32, 32], [32, 64, 64, 128, 256], [256, 128, 64, 64, 32]]},\n        \"filter_sizes\": {'values': [[3, 3, 3, 3, 3], [5, 5, 5, 5, 5]]},\n        \"activation\": {\"values\": [\"ReLU\", \"SiLU\", \"GELU\"]},\n        \"optimizer\": {\"values\": [\"adam\", \"rmsprop\", \"sgd\"]},\n        \"learning_rate\": {\"values\": [1e-3]},\n        \"weight_decay\": {\"values\": [0.0001]},\n        \"momentum\": {\"values\": [0.9]},\n        \"beta\": {\"values\": [0.9]},\n        \"beta1\": {\"values\":[0.9]},\n        \"beta2\": {\"values\": [0.999]},\n        \"epsilon\": {\"values\": [1e-8]},\n        # \"base_dir\": {\"values\":[\"/content/drive/MyDrive/DL_Assignment2/Dataset/inaturalist_12K/\"]},\n        \"base_dir\": {\"values\": [\"/kaggle/input/inaturalist/inaturalist_12K\"]},\n        \"isDataAug\": {\"values\": [\"False\", \"True\"]},\n        \"isBatchNormalization\": {\"values\": [\"True\", \"False\"]},\n        \"dropout\": {\"values\": [0.2, 0.3]},\n        \"n_neurons_denseLayer\": {\"values\": [128]}\n    }\n}\n\n\ndef findOutputs(cnn, inputDataLoader):\n  cnn.eval()  # setting the model to evaluation model\n  outputs = []\n  total_loss = 0.0\n  n_correct = 0\n  n_samples = 0\n\n  with torch.no_grad():\n    for batch_idx, (x_batch, y_batch) in enumerate(inputDataLoader):\n      x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n      batch_outputs = cnn(x_batch)\n\n      loss = nn.CrossEntropyLoss()(batch_outputs, y_batch)\n      total_loss += loss.item() * x_batch.size(0)\n\n      y_pred_batch = torch.argmax(batch_outputs, dim=1)\n      n_correct += (y_pred_batch == y_batch).sum().item()\n      n_samples += x_batch.size(0)\n\n      outputs.append(batch_outputs)\n\n  outputs = torch.cat(outputs)\n  accuracy = (n_correct * 100.0) / n_samples\n  avg_loss = total_loss / n_samples\n  return outputs, accuracy, avg_loss\n\ndef trainNeuralNetwork_sweep():\n  wandb.init(mode=\"online\")\n  args = wandb.config\n  train_loader, test_loader, val_loader, num_classes = load_data(args[\"base_dir\"], args[\"isDataAug\"])\n  activationFun = args[\"activation\"]\n  optimizer = args[\"optimizer\"]\n  learning_rate = args[\"learning_rate\"]\n  momentum = args[\"momentum\"]\n  beta = args[\"beta\"]\n  beta1 = args[\"beta1\"]\n  beta2 = args[\"beta2\"]\n  epsilon = args[\"epsilon\"]\n  weight_decay = args[\"weight_decay\"]\n  dropout = args[\"dropout\"]\n  num_filters = args[\"num_filters\"]\n  filter_sizes = args[\"filter_sizes\"]\n  n_neurons_denseLayer = args[\"n_neurons_denseLayer\"]\n  isBatchNormalization = args[\"isBatchNormalization\"]\n  isDataAug = args[\"isDataAug\"]\n\n  wandb.run.name = f\"{activationFun}_{optimizer}_{dropout}_{n_neurons_denseLayer}_DataAug-{isDataAug}_BatchNorm-{isBatchNormalization}\"\n  best_val_accuracy = 0.0\n  best_accuracy_epoch = -1\n\n  cnn = ConvolutionalNeuralNetwork(num_classes,\n                                   num_filters, filter_sizes,\n                                   activationFun, optimizer,\n                                   n_neurons_denseLayer,\n                                   isBatchNormalization, dropout,\n                                   learning_rate,\n                                   momentum, beta,\n                                   beta1, beta2,\n                                   epsilon, weight_decay)\n  cnn.to(device)\n\n  epochs = 10\n  for epochNum in range(epochs):\n    print(f\"Epoch {epochNum}:\")\n    for batch_idx, (x_batch, y_batch) in enumerate(train_loader):\n      if(batch_idx % 40 == 0):\n        print(f\"Batch idx {batch_idx} running\")\n      x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n      cnn.optimizer.zero_grad()\n      outputs = cnn(x_batch)\n      cnn.backward(outputs, y_batch)\n      cnn.updateWeights()\n\n    # Validation accuracy\n    val_outputs, val_accuracy, val_loss = findOutputs(cnn, val_loader)\n    wandb.run.summary[\"metric_name\"] = val_accuracy\n    print(f\"validation: loss={val_loss}, accuracy={val_accuracy}\")\n\n    # Train accuracy\n    train_outputs, train_accuracy, train_loss = findOutputs(cnn, train_loader)\n    print(f\"training: loss={train_loss}, training={train_accuracy}\")\n\n    if val_accuracy > best_val_accuracy:\n      best_val_accuracy = val_accuracy\n      best_accuracy_epoch = epochNum\n      wandb.run.summary[\"best_val_accuracy\"] = best_val_accuracy\n      wandb.run.summary[\"best_accuracy_epoch\"] = best_accuracy_epoch\n\n    wandb.log({\n        \"epoch\": epochNum + 1,\n        \"val_loss\": val_loss,\n        \"val_accuracy\": val_accuracy,\n        \"train_loss\": train_loss,\n        \"train_accuracy\": train_accuracy\n        },commit=True)\n      \n  wandb.log({\n      \"best_acc_epoch\": best_accuracy_epoch,\n      \"best_val_accuracy\": best_val_accuracy\n  })\n  del cnn\n  torch.cuda.empty_cache()\n\n  wandb.finish()","metadata":{"id":"zEGF79uTtolO","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T10:03:14.490935Z","iopub.execute_input":"2025-04-18T10:03:14.491205Z","iopub.status.idle":"2025-04-18T10:03:14.504961Z","shell.execute_reply.started":"2025-04-18T10:03:14.491183Z","shell.execute_reply":"2025-04-18T10:03:14.504310Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"wandb.login(key=\"x\")\nwandb_id = wandb.sweep(sweep_configuration, project=\"DA6401_Assignment2\")\nwandb.agent(wandb_id, function=trainNeuralNetwork_sweep)","metadata":{"id":"RIw7bCO8CUU7","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T10:03:18.375537Z","iopub.execute_input":"2025-04-18T10:03:18.375784Z","iopub.status.idle":"2025-04-18T10:55:56.801265Z","shell.execute_reply.started":"2025-04-18T10:03:18.375768Z","shell.execute_reply":"2025-04-18T10:55:56.798856Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"name":"stdout","text":"Create sweep with ID: iey9548t\nSweep URL: https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/sweeps/iey9548t\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8m01mlle with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: GELU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbase_dir: /kaggle/input/inaturalist/inaturalist_12K\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta: 0.9\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta1: 0.9\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta2: 0.999\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepsilon: 1e-08\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [5, 5, 5, 5, 5]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tisBatchNormalization: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tisDataAug: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_neurons_denseLayer: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: [32, 32, 32, 32, 32]\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_100326-8m01mlle</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/8m01mlle' target=\"_blank\">floral-sweep-1</a></strong> to <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/sweeps/iey9548t' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/sweeps/iey9548t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/sweeps/iey9548t' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/sweeps/iey9548t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/8m01mlle' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/8m01mlle</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 0:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=2.1231721992492676, accuracy=25.65\ntraining: loss=2.1231721992492676, training=25.65\nEpoch 1:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=2.0430052852630616, accuracy=25.3\ntraining: loss=2.0430052852630616, training=25.3\nEpoch 2:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=1.998781997680664, accuracy=29.0\ntraining: loss=1.998781997680664, training=29.0\nEpoch 3:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=1.9636973457336426, accuracy=29.35\ntraining: loss=1.9636973457336426, training=29.35\nEpoch 4:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=1.9445332355499267, accuracy=31.65\ntraining: loss=1.9445332355499267, training=31.65\nEpoch 5:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=1.859632541656494, accuracy=34.2\ntraining: loss=1.859632541656494, training=34.2\nEpoch 6:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=1.891740879058838, accuracy=33.6\ntraining: loss=1.891740879058838, training=33.6\nEpoch 7:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=1.8992695388793945, accuracy=34.7\ntraining: loss=1.8992695388793945, training=34.7\nEpoch 8:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=1.8505936269760133, accuracy=34.35\ntraining: loss=1.8505936269760133, training=34.35\nEpoch 9:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=1.843267617225647, accuracy=35.2\ntraining: loss=1.843267617225647, training=35.2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▂▃▄▄▆▆▆▇█</td></tr><tr><td>train_loss</td><td>█▆▅▅▄▃▃▃▂▁</td></tr><tr><td>validation_accuracy</td><td>▁▁▄▄▅▇▇█▇█</td></tr><tr><td>validation_loss</td><td>█▆▅▄▄▁▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_model_path</td><td>/kaggle/working/best...</td></tr><tr><td>best_val_accuracy</td><td>35.2</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>metric_name</td><td>35.2</td></tr><tr><td>train_accuracy</td><td>41.04263</td></tr><tr><td>train_loss</td><td>1.6927</td></tr><tr><td>validation_accuracy</td><td>35.2</td></tr><tr><td>validation_loss</td><td>1.84327</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">GELU_sgd_0.2_128_DataAug-True_BatchNorm-True</strong> at: <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/8m01mlle' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/8m01mlle</a><br> View project at: <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_100326-8m01mlle/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: d0t6ofj1 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: GELU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbase_dir: /kaggle/input/inaturalist/inaturalist_12K\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta: 0.9\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta1: 0.9\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta2: 0.999\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepsilon: 1e-08\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [3, 3, 3, 3, 3]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tisBatchNormalization: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tisDataAug: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_neurons_denseLayer: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: [256, 128, 64, 64, 32]\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_102235-d0t6ofj1</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/d0t6ofj1' target=\"_blank\">comic-sweep-2</a></strong> to <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/sweeps/iey9548t' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/sweeps/iey9548t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/sweeps/iey9548t' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/sweeps/iey9548t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/d0t6ofj1' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/d0t6ofj1</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 0:\nBatch idx 0 running\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">GELU_adam_0.3_128_DataAug-True_BatchNorm-True</strong> at: <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/d0t6ofj1' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/d0t6ofj1</a><br> View project at: <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_102235-d0t6ofj1/logs</code>"},"metadata":{}},{"name":"stderr","text":"Run d0t6ofj1 errored:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n    self._function()\n  File \"/tmp/ipykernel_31/2685196665.py\", line 101, in trainNeuralNetwork_sweep\n    cnn.backward(outputs, y_batch)\n  File \"/tmp/ipykernel_31/3434670670.py\", line 76, in backward\n    loss.backward()\n  File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 581, in backward\n    torch.autograd.backward(\n  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n    _engine_run_backward(\n  File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntorch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.06 GiB. GPU 0 has a total capacity of 15.89 GiB of which 1.61 GiB is free. Process 6124 has 14.28 GiB memory in use. Of the allocated memory 11.55 GiB is allocated by PyTorch, and 2.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run d0t6ofj1 errored:\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/wandb/agents/pyagent.py\", line 306, in _run_job\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/2685196665.py\", line 101, in trainNeuralNetwork_sweep\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     cnn.backward(outputs, y_batch)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/tmp/ipykernel_31/3434670670.py\", line 76, in backward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     loss.backward()\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\", line 581, in backward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     torch.autograd.backward(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\", line 347, in backward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     _engine_run_backward(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\", line 825, in _engine_run_backward\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.06 GiB. GPU 0 has a total capacity of 15.89 GiB of which 1.61 GiB is free. Process 6124 has 14.28 GiB memory in use. Of the allocated memory 11.55 GiB is allocated by PyTorch, and 2.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ygkongs4 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: ReLU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbase_dir: /kaggle/input/inaturalist/inaturalist_12K\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta: 0.9\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta1: 0.9\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta2: 0.999\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepsilon: 1e-08\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [3, 3, 3, 3, 3]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tisBatchNormalization: False\n\u001b[34m\u001b[1mwandb\u001b[0m: \tisDataAug: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_neurons_denseLayer: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: [32, 32, 32, 32, 32]\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_102257-ygkongs4</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/ygkongs4' target=\"_blank\">wandering-sweep-3</a></strong> to <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/sweeps/iey9548t' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/sweeps/iey9548t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/sweeps/iey9548t' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/sweeps/iey9548t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/ygkongs4' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/ygkongs4</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 0:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=2.13199680519104, accuracy=23.5\ntraining: loss=2.13199680519104, training=23.5\nEpoch 1:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=2.0159440078735353, accuracy=27.3\ntraining: loss=2.0159440078735353, training=27.3\nEpoch 2:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=1.9688703212738037, accuracy=31.0\ntraining: loss=1.9688703212738037, training=31.0\nEpoch 3:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=1.9409629459381104, accuracy=32.35\ntraining: loss=1.9409629459381104, training=32.35\nEpoch 4:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=1.9274802265167237, accuracy=32.6\ntraining: loss=1.9274802265167237, training=32.6\nEpoch 5:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=1.8977783069610596, accuracy=34.0\ntraining: loss=1.8977783069610596, training=34.0\nEpoch 6:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=1.9245554771423339, accuracy=31.45\ntraining: loss=1.9245554771423339, training=31.45\nEpoch 7:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=1.857542730331421, accuracy=34.15\ntraining: loss=1.857542730331421, training=34.15\nEpoch 8:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=1.8737850122451782, accuracy=34.15\ntraining: loss=1.8737850122451782, training=34.15\nEpoch 9:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=1.8480082149505614, accuracy=35.65\ntraining: loss=1.8480082149505614, training=35.65\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▂▅▅▅▆▆███</td></tr><tr><td>train_loss</td><td>█▆▄▄▄▃▃▁▂▁</td></tr><tr><td>validation_accuracy</td><td>▁▃▅▆▆▇▆▇▇█</td></tr><tr><td>validation_loss</td><td>█▅▄▃▃▂▃▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_model_path</td><td>/kaggle/working/best...</td></tr><tr><td>best_val_accuracy</td><td>35.65</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>metric_name</td><td>35.65</td></tr><tr><td>train_accuracy</td><td>39.2299</td></tr><tr><td>train_loss</td><td>1.73352</td></tr><tr><td>validation_accuracy</td><td>35.65</td></tr><tr><td>validation_loss</td><td>1.84801</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">ReLU_sgd_0.3_128_DataAug-True_BatchNorm-False</strong> at: <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/ygkongs4' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/ygkongs4</a><br> View project at: <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_102257-ygkongs4/logs</code>"},"metadata":{}},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cr86ffi3 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: SiLU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbase_dir: /kaggle/input/inaturalist/inaturalist_12K\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta: 0.9\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta1: 0.9\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeta2: 0.999\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepsilon: 1e-08\n\u001b[34m\u001b[1mwandb\u001b[0m: \tfilter_sizes: [5, 5, 5, 5, 5]\n\u001b[34m\u001b[1mwandb\u001b[0m: \tisBatchNormalization: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tisDataAug: True\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n\u001b[34m\u001b[1mwandb\u001b[0m: \tmomentum: 0.9\n\u001b[34m\u001b[1mwandb\u001b[0m: \tn_neurons_denseLayer: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_filters: [32, 64, 64, 128, 256]\n\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: rmsprop\n\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.6"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250418_104213-cr86ffi3</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/cr86ffi3' target=\"_blank\">sandy-sweep-4</a></strong> to <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/sweeps/iey9548t' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/sweeps/iey9548t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/sweeps/iey9548t' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/sweeps/iey9548t</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/cr86ffi3' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/cr86ffi3</a>"},"metadata":{}},{"name":"stdout","text":"Epoch 0:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=2.4753534870147704, accuracy=15.4\ntraining: loss=2.4753534870147704, training=15.4\nEpoch 1:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=2.103593620300293, accuracy=23.15\ntraining: loss=2.103593620300293, training=23.15\nEpoch 2:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=2.0029942207336426, accuracy=29.95\ntraining: loss=2.0029942207336426, training=29.95\nEpoch 3:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=2.028902931213379, accuracy=29.95\ntraining: loss=2.028902931213379, training=29.95\nEpoch 4:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=2.181956775665283, accuracy=30.5\ntraining: loss=2.181956775665283, training=30.5\nEpoch 5:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=1.9146376838684083, accuracy=33.25\ntraining: loss=1.9146376838684083, training=33.25\nEpoch 6:\nBatch idx 0 running\nBatch idx 40 running\nBatch idx 80 running\nBatch idx 120 running\nvalidation: loss=1.9081096115112304, accuracy=32.35\ntraining: loss=1.9081096115112304, training=32.35\nEpoch 7:\nBatch idx 0 running\nBatch idx 40 running\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▅▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▄▆▆▆██</td></tr><tr><td>train_loss</td><td>█▄▃▃▅▂▁</td></tr><tr><td>validation_accuracy</td><td>▁▄▇▇▇██</td></tr><tr><td>validation_loss</td><td>█▃▂▂▄▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>7</td></tr><tr><td>metric_name</td><td>32.35</td></tr><tr><td>train_accuracy</td><td>35.65446</td></tr><tr><td>train_loss</td><td>1.81513</td></tr><tr><td>validation_accuracy</td><td>32.35</td></tr><tr><td>validation_loss</td><td>1.90811</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">SiLU_rmsprop_0.2_128_DataAug-True_BatchNorm-True</strong> at: <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/cr86ffi3' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2/runs/cr86ffi3</a><br> View project at: <a href='https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2' target=\"_blank\">https://wandb.ai/nikhithaa-iit-madras/DA6401_Assignment2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250418_104213-cr86ffi3/logs</code>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# import os\nprint(os.listdir('/kaggle/working'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T10:57:21.389980Z","iopub.execute_input":"2025-04-18T10:57:21.390516Z","iopub.status.idle":"2025-04-18T10:57:21.394880Z","shell.execute_reply.started":"2025-04-18T10:57:21.390491Z","shell.execute_reply":"2025-04-18T10:57:21.393885Z"}},"outputs":[{"name":"stdout","text":"['wandb', '.virtual_documents', 'best_model.pth']\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}